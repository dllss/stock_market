{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "base_path = 'stock'\n",
    "\n",
    "market_map = {'主板':0, '中小板':1}\n",
    "exchange_map = {'SZSE':0, 'SSE':1}\n",
    "is_hs_map = {'S':0, 'N':1, 'H':2}\n",
    "\n",
    "area_map = {'深圳': 0, '北京': 1, '吉林': 2, '江苏': 3, '辽宁': 4, '广东': 5, '安徽': 6, '四川': 7, '浙江': 8,\n",
    "            '湖南': 9, '河北': 10, '新疆': 11, '山东': 12, '河南': 13, '山西': 14, '江西': 15, '青海': 16, \n",
    "            '湖北': 17, '内蒙': 18, '海南': 19, '重庆': 20, '陕西': 21, '福建': 22, '广西': 23, '天津': 24, \n",
    "            '云南': 25, '贵州': 26, '甘肃': 27, '宁夏': 28, '黑龙江': 29, '上海': 30, '西藏': 31}\n",
    "\n",
    "industry_map = {'银行': 0, '全国地产': 1, '生物制药': 2, '环境保护': 3, '区域地产': 4, '酒店餐饮': 5, '运输设备': 6, \n",
    " '综合类': 7, '建筑工程': 8, '玻璃': 9, '家用电器': 10, '文教休闲': 11, '其他商业': 12, '元器件': 13, \n",
    " 'IT设备': 14, '其他建材': 15, '汽车服务': 16, '火力发电': 17, '医药商业': 18, '汽车配件': 19, '广告包装': 20, \n",
    " '轻工机械': 21, '新型电力': 22, '饲料': 23, '电气设备': 24, '房产服务': 25, '石油加工': 26, '铅锌': 27, '农业综合': 28,\n",
    " '批发业': 29, '通信设备': 30, '旅游景点': 31, '港口': 32, '机场': 33, '石油贸易': 34, '空运': 35, '医疗保健': 36,\n",
    " '商贸代理': 37, '化学制药': 38, '影视音像': 39, '工程机械': 40, '软件服务': 41, '证券': 42, '化纤': 43, '水泥': 44, \n",
    " '专用机械': 45, '供气供热': 46, '农药化肥': 47, '机床制造': 48, '多元金融': 49, '百货': 50, '中成药': 51, '路桥': 52, \n",
    " '造纸': 53, '食品': 54, '黄金': 55, '化工原料': 56, '矿物制品': 57, '水运': 58, '日用化工': 59, '机械基件': 60, \n",
    " '汽车整车': 61, '煤炭开采': 62, '铁路': 63, '染料涂料': 64, '白酒': 65, '林业': 66, '水务': 67, '水力发电': 68, \n",
    " '互联网': 69, '旅游服务': 70, '纺织': 71, '铝': 72, '保险': 73, '园区开发': 74, '小金属': 75, '铜': 76, '普钢': 77, \n",
    " '航空': 78, '特种钢': 79, '种植业': 80, '出版业': 81, '焦炭加工': 82, '啤酒': 83, '公路': 84, '超市连锁': 85, \n",
    " '钢加工': 86, '渔业': 87, '农用机械': 88, '软饮料': 89, '化工机械': 90, '塑料': 91, '红黄酒': 92, '橡胶': 93, '家居用品': 94,\n",
    " '摩托车': 95, '电器仪表': 96, '服饰': 97, '仓储物流': 98, '纺织机械': 99, '电器连锁': 100, '装修装饰': 101, '半导体': 102, \n",
    " '电信运营': 103, '石油开采': 104, '乳制品': 105, '商品城': 106, '公共交通': 107, '船舶': 108, '陶瓷': 109}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JudgeST(x):\n",
    "    if 'ST' in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def GetMA(df, col_name, rolling_day):\n",
    "    tmp_array = df[col_name].values.reshape(-1)\n",
    "    df.loc[ rolling_day:, col_name + '_'+str(rolling_day)] = (tmp_array[0:-rolling_day] - \n",
    "                                                              tmp_array[rolling_day:]) / tmp_array[0:-rolling_day]\n",
    "    return df\n",
    "\n",
    "col = ['ma'+str(i) for i in [5, 10, 13]] + ['ma_v_'+str(i) for i in [5, 10, 13]]\n",
    "\n",
    "company_info = pd.read_csv(os.path.join(base_path, 'company_info.csv'), encoding='ANSI')\n",
    "company_info['is_ST'] = company_info['name'].apply(JudgeST)\n",
    "# 丢弃一些多余的信息\n",
    "company_info.drop(['index', 'symbol', 'fullname'], axis=1, inplace=True)\n",
    "company_info.dropna(inplace=True)\n",
    "company_info['market'] = company_info['market'].map(market_map)\n",
    "company_info['exchange'] = company_info['exchange'].map(exchange_map)\n",
    "company_info['is_hs'] = company_info['is_hs'].map(is_hs_map)\n",
    "\n",
    "\n",
    "# 读取指数信息\n",
    "stock_index_info = pd.DataFrame()\n",
    "index = ['000001.SH', '000016.SH', '000002.SH', '399001.SZ', '399007.SZ', '399008.SZ', '399101.SZ',\n",
    "         '399102.SZ']\n",
    "for ts_code in index:\n",
    "    tmp_df = pd.read_csv(os.path.join(base_path,  'OldData', ts_code + '_NormalData.csv'))\n",
    "    # 特征工程\n",
    "#         tmp_df = FeatureEngineering(tmp_df)\n",
    "    stock_index_info = pd.concat((stock_index_info, tmp_df)) \n",
    "    break\n",
    "#     transaction_day = len(tmp_df) \n",
    "tmp_list = list(tmp_df['trade_date'].sort_values())\n",
    "date_map = dict(zip(tmp_list, range(len(tmp_list))))\n",
    "\n",
    "# 读取股票交易信息\n",
    "stock_info = pd.DataFrame()\n",
    "remove_stock = []\n",
    "tmp_list = []\n",
    "for ts_code in tqdm.tqdm(company_info['ts_code']):\n",
    "    try:\n",
    "        tmp_df = pd.read_csv(os.path.join(base_path,  'OldData', ts_code + '_NormalData.csv'))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # 还需要去除一些停牌时间很久的企业，后期加\n",
    "    if len(tmp_df) < 100:  # 去除一些上市不久的企业\n",
    "        remove_stock.append(ts_code)\n",
    "        continue\n",
    "    tmp_df = tmp_df.sort_values('trade_date', ascending=True).reset_index(drop=True)    \n",
    "    for tmp_col in col:\n",
    "        for rolling_day in [3]:\n",
    "            tmp_df = GetMA(tmp_df, tmp_col, rolling_day)\n",
    "    \n",
    "    \n",
    "\n",
    "    tmp_list.append(tmp_df)\n",
    "stock_info = pd.concat(tmp_list)\n",
    "stock_info = stock_info.reset_index(drop=True)\n",
    "ts_code_map = dict(zip(stock_info['ts_code'].unique(), range(stock_info['ts_code'].nunique())))\n",
    "\n",
    "\n",
    "stock_info = stock_info.reset_index(drop=True)\n",
    "stock_info['ts_code_id'] = stock_info['ts_code'].map(ts_code_map)\n",
    "\n",
    "stock_info['trade_date_id'] = stock_info['trade_date'].map(date_map)\n",
    "stock_info['ts_date_id'] = (10000 + stock_info['ts_code_id']) * 10000 + stock_info['trade_date_id']\n",
    "stock_info = stock_info.merge(company_info, how='left', on='ts_code')\n",
    "stock_info_copy = stock_info.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_info = stock_info.drop_duplicates(subset=['ts_date_id'])\n",
    "len(stock_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stock_info_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取月份 和 星期几\n",
    "def get_weekday(x):\n",
    "    x = str(x)\n",
    "    return datetime.datetime.fromtimestamp(time.mktime(time.strptime(x, \"%Y%m%d\"))).weekday()\n",
    "# stock_info['month'] = stock_info['trade_date'].apply(lambda x: int(str(x)[4:6]))\n",
    "stock_info['weekday'] = stock_info['trade_date'].apply(get_weekday)\n",
    "# feature_col.append('month')\n",
    "feature_col.append('weekday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加涨跌停信息\n",
    "limit_info = pd.read_csv('limit.csv')\n",
    "limit_info.drop('file', axis=1, inplace=True)\n",
    "limit_info['U-D'] = limit_info['U'] - limit_info['D']\n",
    "limit_info = limit_info.rename(columns={'date':'trade_date'})\n",
    "stock_info = stock_info.merge(limit_info[['U-D', 'trade_date']], on='trade_date', how='left')\n",
    "feature_col.append('U-D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 求相对的vol 这里与21均线比较\n",
    "stock_info['vol'] = (stock_info['vol'] - stock_info['ma_v_21']) / stock_info['ma_v_21']\n",
    "feature_col.append('vol')\n",
    "\n",
    "#转换low close等\n",
    "col = ['open', 'high', 'low', 'high', 'pre_close']\n",
    "for tmp_col in col:\n",
    "    stock_info[tmp_col+'_transform'] = (stock_info[tmp_col] - stock_info['ma5']) / stock_info['ma5']\n",
    "    feature_col.append(tmp_col+'_transform')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加大盘指数信息\n",
    "tmp_df = pd.read_csv(os.path.join(base_path,  'OldData', '000001.SH' + '_NormalData.csv'))\n",
    "for tmp_col in ['amount', 'pre_close']:\n",
    "    tmp_df = tmp_df.rename(columns={tmp_col: tmp_col + '_index_000001'})\n",
    "    stock_info = stock_info.merge(tmp_df[['trade_date', tmp_col + '_index_000001']], on='trade_date', how='left')\n",
    "\n",
    "for tmp_col in ['amount_index_000001', 'pre_close_index_000001', 'amount', 'pre_close']:\n",
    "    print(tmp_col)\n",
    "    for i in range(3):\n",
    "        tmp_df = stock_info[['ts_date_id', tmp_col]]\n",
    "        new_col_name = tmp_col + '_shift_{}'.format(i+1)\n",
    "        tmp_df = tmp_df.rename(columns={tmp_col:new_col_name})\n",
    "        feature_col.append(new_col_name)\n",
    "        tmp_df['ts_date_id'] = tmp_df['ts_date_id'] + i + 1\n",
    "        stock_info = stock_info.merge(tmp_df, how='left', on='ts_date_id')\n",
    "    for i in range(3):\n",
    "        new_col_name = tmp_col + '_shift_{}'.format(i+1)\n",
    "        stock_info[new_col_name] = (stock_info[tmp_col] - stock_info[new_col_name]) / stock_info[new_col_name]\n",
    "#         feature_col.append(new_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加资金流向\n",
    "df_list = []\n",
    "col = ['buy_md_vol', 'sell_md_vol', 'buy_lg_vol', 'sell_lg_vol', \n",
    "       'buy_elg_vol', 'sell_elg_vol', 'net_mf_vol'] #'buy_sm_vol', 'sell_sm_vol',\n",
    "for ts_code in tqdm.tqdm(company_info['ts_code']):\n",
    "    try:\n",
    "        tmp_df = pd.read_csv(os.path.join(base_path,  'MoneyData', ts_code + '.csv'))\n",
    "    except:\n",
    "        pass\n",
    "    transform_col = []\n",
    "    # 还需要去除一些停牌时间很久的企业，后期加\n",
    "    if len(tmp_df) < 100:  # 去除一些上市不久的企业\n",
    "        remove_stock.append(ts_code)\n",
    "        continue\n",
    "    tmp_df = tmp_df.sort_values('trade_date', ascending=True).reset_index(drop=True)  \n",
    "    drop_col = []\n",
    "#     tmp_df.drop(['buy_sm_amount', 'sell_sm_amount', 'buy_md_amount', 'sell_md_amount', 'buy_lg_amount', 'sell_lg_amount', \n",
    "#                 'buy_elg_amount', 'sell_elg_amount', 'net_mf_amount'])\n",
    "    tmp_df['diff_md'] = tmp_df['buy_md_vol'] - tmp_df['sell_md_vol']\n",
    "    tmp_df['diff_lg'] = tmp_df['buy_lg_vol'] - tmp_df['sell_lg_vol']\n",
    "    tmp_df['diff_elg'] = tmp_df['buy_elg_vol'] - tmp_df['sell_elg_vol']\n",
    "    rolling_day = 5\n",
    "    for tmp_col in ['buy_md_vol', 'buy_lg_vol', 'buy_elg_vol', 'diff_md', 'diff_lg', 'diff_elg']:\n",
    "        tmp_df[tmp_col+'_'+str(rolling_day)] = tmp_df[tmp_col].rolling(rolling_day).mean()\n",
    "        tmp_df[tmp_col+'_transform'] = (tmp_df[tmp_col] - tmp_df[tmp_col+'_'+str(rolling_day)]) / tmp_df[tmp_col+'_'+str(rolling_day)]\n",
    "        transform_col.append(tmp_col+'_transform')    \n",
    "    transfom_col = ['buy_md_vol', 'buy_lg_vol', 'buy_elg_vol', 'diff_md', 'diff_lg', 'diff_elg']        \n",
    "    for shift_day in [1, 2, 3]:\n",
    "        for tmp_col in ['buy_md_vol', 'buy_lg_vol', 'buy_elg_vol', 'diff_md', 'diff_lg', 'diff_elg']:\n",
    "            tmp_array = tmp_df[tmp_col].values.reshape(-1)\n",
    "            tmp_df.loc[shift_day:, tmp_col + '_shift_'+str(shift_day)] = tmp_array[0:-shift_day]\n",
    "            tmp_df[tmp_col + '_shift_'+str(shift_day)] = \\\n",
    "            (tmp_df[tmp_col + '_shift_'+str(shift_day)] - tmp_df[tmp_col+'_'+str(rolling_day)]) / tmp_df[tmp_col+'_'+str(rolling_day)]\n",
    "            transform_col.append(tmp_col + '_shift_'+str(shift_day))    \n",
    "    df_list.append(tmp_df[['trade_date', 'ts_code']+transform_col])\n",
    "    \n",
    "df_all = pd.concat(df_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = feature_col + [tmp_col for tmp_col in df_all.columns if tmp_col not in['trade_date', 'ts_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_info = stock_info.merge(df_all, on=['trade_date', 'ts_code'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col.append('turnover_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_info.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标签制作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_label\n",
    "# stock_info = stock_info_copy.copy()\n",
    "use_col = []\n",
    "for i in range(3):\n",
    "    tmp_df = stock_info[['ts_date_id', 'high', 'low']]\n",
    "    tmp_df = tmp_df.rename(columns={'high':'high_shift_{}'.format(i+1), 'low':'low_shift_{}'.format(i+1)})\n",
    "    use_col.append('high_shift_{}'.format(i+1))\n",
    "    use_col.append('low_shift_{}'.format(i+1))\n",
    "    tmp_df['ts_date_id'] = tmp_df['ts_date_id'] - i - 1\n",
    "    stock_info = stock_info.merge(tmp_df, how='left', on='ts_date_id')\n",
    "\n",
    "stock_info.dropna(inplace=True)\n",
    "\n",
    "for i in range(3):\n",
    "    stock_info['high_shift_{}'.format(i+1)] = (stock_info['high_shift_{}'.format(i+1)] - stock_info['close']) / stock_info['close']\n",
    "    stock_info['low_shift_{}'.format(i+1)] = (stock_info['low_shift_{}'.format(i+1)] - stock_info['close']) / stock_info['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_array = stock_info[use_col].values\n",
    "max_increse = np.max(tmp_array, axis=1)\n",
    "min_increse = np.min(tmp_array, axis=1)\n",
    "stock_info['label_max'] = max_increse\n",
    "stock_info['label_min'] = min_increse\n",
    "stock_info['label_final'] = (stock_info['label_max'] > 0.06) & (stock_info['label_min'] > -0.03)\n",
    "stock_info['label_final'] = stock_info['label_final'].apply(lambda x: int(x))\n",
    "\n",
    "stock_info = stock_info.reset_index(drop=True)\n",
    "# stock_info.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col=['weekday', 'U-D', 'vol', 'open_transform', 'high_transform', 'low_transform', 'high_transform', 'pre_close_transform', \n",
    " 'amount_index_000001_shift_1', 'amount_index_000001_shift_2', 'amount_index_000001_shift_3', 'pre_close_index_000001_shift_1', \n",
    " 'pre_close_index_000001_shift_2', 'pre_close_index_000001_shift_3', 'amount_shift_1', 'amount_shift_2', 'amount_shift_3',\n",
    " 'pre_close_shift_1', 'pre_close_shift_2', 'pre_close_shift_3', 'turnover_rate', 'buy_md_vol_shift_1', 'buy_lg_vol_shift_1', \n",
    " 'buy_elg_vol_shift_1', 'diff_md_shift_1', 'diff_lg_shift_1', 'diff_elg_shift_1', 'buy_md_vol_shift_2', 'buy_lg_vol_shift_2', \n",
    " 'buy_elg_vol_shift_2', 'diff_md_shift_2', 'diff_lg_shift_2', 'diff_elg_shift_2']\n",
    "\n",
    "# 'buy_md_vol_shift_1', 'buy_lg_vol_shift_1', \n",
    "#  'buy_elg_vol_shift_1', 'diff_md_shift_1', 'diff_lg_shift_1', 'diff_elg_shift_1', 'buy_md_vol_shift_2', 'buy_lg_vol_shift_2', \n",
    "#  'buy_elg_vol_shift_2', 'diff_md_shift_2', 'diff_lg_shift_2', 'diff_elg_shift_2', 'buy_md_vol_shift_3', 'buy_lg_vol_shift_3', \n",
    "#  'buy_elg_vol_shift_3', 'diff_md_shift_3', 'diff_lg_shift_3', 'diff_elg_shift_3'\n",
    "\n",
    "# 'buy_md_vol_transform', 'buy_lg_vol_transform',\n",
    "#  'buy_elg_vol_transform', 'diff_md_transform', 'diff_lg_transform', 'diff_elg_transform', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trn_col = feature_col\n",
    "# 'high', 'low', 'close', 'pre_close',\n",
    "trn_col = list(set(trn_col))\n",
    "label = 'label_final'\n",
    "# trn_date_min = 20170103\n",
    "# trn_date_max = 20190416\n",
    "# val_date_min = 20190417\n",
    "# val_date_max = 20190429\n",
    "# test_date_min = 20190417\n",
    "# test_date_max = 20191218\n",
    "\n",
    "trn_date_min = 20170103\n",
    "trn_date_max = 20190101\n",
    "val_date_min = 20190101\n",
    "val_date_max = 20190419\n",
    "test_date_min = 20190101\n",
    "test_date_max = 20191218\n",
    "\n",
    "trn_data_idx = (stock_info['trade_date'] >= trn_date_min) & (stock_info['trade_date'] <= trn_date_max) & (stock_info['high']!=stock_info['close'])\n",
    "val_data_idx = (stock_info['trade_date'] >= val_date_min) & (stock_info['trade_date'] <= val_date_max)\n",
    "test_data_idx = (stock_info['trade_date'] >= test_date_min) & (stock_info['trade_date'] <= test_date_max)\n",
    "\n",
    "trn = stock_info[trn_data_idx][trn_col]\n",
    "trn_label = stock_info[trn_data_idx][label].values\n",
    "\n",
    "val = stock_info[val_data_idx][trn_col]\n",
    "val_label = stock_info[val_data_idx][label].values \n",
    "\n",
    "test = stock_info[test_data_idx][trn_col]\n",
    "test_label = stock_info[test_data_idx][label].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rate of 0: %.4f, rate of 1: %.4f' % (np.sum(trn_label==0)/len(trn_label), np.sum(trn_label==1)/len(trn_label)))\n",
    "print('trn data:%d, val data:%d, test data:%d' % (len(trn), len(val), len(test)))\n",
    "print('number of features:%d' % len(trn_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win_score_eval(preds, valid_df):\n",
    "    labels = valid_df.get_label()\n",
    "    preds = np.round(preds)\n",
    "    tp = np.sum((preds==1)&(labels==1))\n",
    "    pp = np.sum(preds==1)\n",
    "    scores = tp/(pp+0.001) + 2.5*tp - pp\n",
    "#     preds = np.argmax(preds.reshape(3, -1), axis=0)\n",
    "#     scores = f1_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    return 'win', scores, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练及评价\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective': 'binary',\n",
    "         'learning_rate': 0.06,\n",
    "         \"boosting\": \"gbdt\",\n",
    "#          \"bagging_freq\": 1,\n",
    "#          \"bagging_seed\": 11,\n",
    "         \"metric\": 'None',\n",
    "         \"verbosity\": -1}\n",
    "trn_data = lgb.Dataset(trn, trn_label)\n",
    "val_data = lgb.Dataset(val, val_label)\n",
    "num_round =1000\n",
    "# clf = lgb.train(param, trn_data, num_round, valid_sets=[trn_data, val_data], verbose_eval=100,\n",
    "#                 early_stopping_rounds=300, feval=win_score_eval)\n",
    "clf = lgb.train(param, trn_data, num_round, verbose_eval=300)\n",
    "# oof_lgb = clf.predict(val, num_iteration=clf.best_iteration)\n",
    "test_lgb = clf.predict(test, num_iteration=clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "        'column': trn_col,\n",
    "        'importance': clf.feature_importance(),\n",
    "    }).sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lgb_final = np.round(oof_lgb)\n",
    "# print(metrics.accuracy_score(val_label, oof_lgb_final))\n",
    "# print(metrics.confusion_matrix(val_label, oof_lgb_final))\n",
    "# tp = np.sum(((oof_lgb_final == 1) & (val_label == 1)))\n",
    "# pp = np.sum(oof_lgb_final == 1)\n",
    "# print('sensitivity:%.3f'% (tp/(pp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_hold = 0.5\n",
    "# oof_test_final = (test_lgb >= 0.69) & (test_lgb <=0.7)\n",
    "oof_test_final = test_lgb >= thresh_hold\n",
    "print(metrics.accuracy_score(test_label, oof_test_final))\n",
    "print(metrics.confusion_matrix(test_label, oof_test_final))\n",
    "tp = np.sum(((oof_test_final == 1) & (test_label == 1)))\n",
    "pp = np.sum(oof_test_final == 1)\n",
    "print('sensitivity:%.3f'% (tp/(pp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_postive_idx = np.argwhere(oof_test_final == 1).reshape(-1)\n",
    "# test_postive_idx = list(range(len(oof_test_final)))\n",
    "test_all_idx = np.argwhere(test_data_idx).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看选了哪些股票\n",
    "tmp_col = ['ts_code', 'name', 'trade_date', 'open', 'high', 'low', 'close', 'pre_close',\n",
    "       'change', 'pct_chg', 'amount', 'is_ST', 'label_max', 'label_min', 'label_final']\n",
    "# stock_info.iloc[test_all_idx[test_postive_idx]]\n",
    "\n",
    "tmp_df = stock_info[tmp_col].iloc[test_all_idx[test_postive_idx]].reset_index()\n",
    "tmp_df['label_prob'] = test_lgb[test_postive_idx]\n",
    "# idx_tmp = tmp_df['is_ST'] == 0\n",
    "# tmp_df.loc[idx_tmp, 'is_limit_up'] = (((tmp_df['close'][idx_tmp]-tmp_df['pre_close'][idx_tmp]) / tmp_df['pre_close'][idx_tmp]) > 0.095)\n",
    "# idx_tmp = tmp_df['is_ST'] == 1\n",
    "# tmp_df.loc[idx_tmp, 'is_limit_up'] = (((tmp_df['close'][idx_tmp]-tmp_df['pre_close'][idx_tmp]) / tmp_df['pre_close'][idx_tmp]) > 0.047)\n",
    "\n",
    "tmp_df['is_limit_up'] = tmp_df['close'] == tmp_df['high']\n",
    "\n",
    "buy_df = tmp_df[(tmp_df['is_limit_up']==False)].reset_index()\n",
    "buy_df.drop(['index', 'level_0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(buy_df), sum(buy_df['label_final']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_info.reset_index().head()\n",
    "# 读取指数信息\n",
    "index_df = pd.read_csv(os.path.join(base_path,  'OldData', '000001.SH' + '_NormalData.csv'))\n",
    "tmp_idx = (index_df['trade_date'] >= test_date_min) & (index_df['trade_date'] <= test_date_max)\n",
    "index_df = index_df.loc[tmp_idx].reset_index()\n",
    "index_df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_idx = (index_df['trade_date'] == test_date_min+1)\n",
    "close1 = index_df[tmp_idx]['close'].values[0]\n",
    "tmp_idx = (index_df['trade_date'] == test_date_max)\n",
    "close2 = index_df[tmp_idx]['close'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "import Account\n",
    "reload(Account)\n",
    "money_init = 100000\n",
    "account = Account.Account(money_init, max_hold_period=3)\n",
    "account.BackTest(buy_df, stock_info_copy, index_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df2 = buy_df[['ts_code', 'trade_date', 'label_prob', 'label_final']]\n",
    "tmp_df2 = tmp_df2.rename(columns={'trade_date':'buy_date'})\n",
    "tmp_df = account.info\n",
    "tmp_df = tmp_df.merge(tmp_df2, on=['ts_code', 'buy_date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_profit = (account.market_value - money_init) / money_init\n",
    "index_profit = (close2 - close1) / close1\n",
    "win_rate = account.victory / (account.victory + account.defeat)\n",
    "print('账户盈利情况:%.4f' % account_profit)\n",
    "print('上证指数浮动情况:%.4f' % index_profit)\n",
    "print('交易胜率:%.4f' % win_rate)\n",
    "print('最大回撤率:%.4f' % account.max_retracement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Draw\n",
    "reload(Draw)\n",
    "%matplotlib inline\n",
    "index_value = list(index_df[index_df['trade_date']==test_date_min+1]['pre_close']) + list(index_df.sort_values('trade_date')['close'])\n",
    "Draw.Draw_Market_Value_Change(0, account.market_value_all, index_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for ts_code, buy_date, sell_date in zip(account.info['ts_code'], account.info['buy_date'], account.info['sell_date']):\n",
    "    Draw.Draw_Stock(ts_code, stock_info, buy_date, sell_date, left_offset=15, right_offset=15)\n",
    "    num = num + 1\n",
    "    if num > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "080da6c26f0a175bdb916ba142774bba8599a404fc80d6d1f14d481a78eeafad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
