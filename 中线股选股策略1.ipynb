{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "import datetime\n",
    "import time\n",
    "from GlobalVariable import encoding_type, base_path\n",
    "\n",
    "market_map = {'主板':0, '中小板':1}\n",
    "exchange_map = {'SZSE':0, 'SSE':1}\n",
    "is_hs_map = {'S':0, 'N':1, 'H':2}\n",
    "\n",
    "area_map = {'深圳': 0, '北京': 1, '吉林': 2, '江苏': 3, '辽宁': 4, '广东': 5, '安徽': 6, '四川': 7, '浙江': 8,\n",
    "            '湖南': 9, '河北': 10, '新疆': 11, '山东': 12, '河南': 13, '山西': 14, '江西': 15, '青海': 16, \n",
    "            '湖北': 17, '内蒙': 18, '海南': 19, '重庆': 20, '陕西': 21, '福建': 22, '广西': 23, '天津': 24, \n",
    "            '云南': 25, '贵州': 26, '甘肃': 27, '宁夏': 28, '黑龙江': 29, '上海': 30, '西藏': 31}\n",
    "\n",
    "industry_map = {'银行': 0, '全国地产': 1, '生物制药': 2, '环境保护': 3, '区域地产': 4, '酒店餐饮': 5, '运输设备': 6, \n",
    " '综合类': 7, '建筑工程': 8, '玻璃': 9, '家用电器': 10, '文教休闲': 11, '其他商业': 12, '元器件': 13, \n",
    " 'IT设备': 14, '其他建材': 15, '汽车服务': 16, '火力发电': 17, '医药商业': 18, '汽车配件': 19, '广告包装': 20, \n",
    " '轻工机械': 21, '新型电力': 22, '饲料': 23, '电气设备': 24, '房产服务': 25, '石油加工': 26, '铅锌': 27, '农业综合': 28,\n",
    " '批发业': 29, '通信设备': 30, '旅游景点': 31, '港口': 32, '机场': 33, '石油贸易': 34, '空运': 35, '医疗保健': 36,\n",
    " '商贸代理': 37, '化学制药': 38, '影视音像': 39, '工程机械': 40, '软件服务': 41, '证券': 42, '化纤': 43, '水泥': 44, \n",
    " '专用机械': 45, '供气供热': 46, '农药化肥': 47, '机床制造': 48, '多元金融': 49, '百货': 50, '中成药': 51, '路桥': 52, \n",
    " '造纸': 53, '食品': 54, '黄金': 55, '化工原料': 56, '矿物制品': 57, '水运': 58, '日用化工': 59, '机械基件': 60, \n",
    " '汽车整车': 61, '煤炭开采': 62, '铁路': 63, '染料涂料': 64, '白酒': 65, '林业': 66, '水务': 67, '水力发电': 68, \n",
    " '互联网': 69, '旅游服务': 70, '纺织': 71, '铝': 72, '保险': 73, '园区开发': 74, '小金属': 75, '铜': 76, '普钢': 77, \n",
    " '航空': 78, '特种钢': 79, '种植业': 80, '出版业': 81, '焦炭加工': 82, '啤酒': 83, '公路': 84, '超市连锁': 85, \n",
    " '钢加工': 86, '渔业': 87, '农用机械': 88, '软饮料': 89, '化工机械': 90, '塑料': 91, '红黄酒': 92, '橡胶': 93, '家居用品': 94,\n",
    " '摩托车': 95, '电器仪表': 96, '服饰': 97, '仓储物流': 98, '纺织机械': 99, '电器连锁': 100, '装修装饰': 101, '半导体': 102, \n",
    " '电信运营': 103, '石油开采': 104, '乳制品': 105, '商品城': 106, '公共交通': 107, '船舶': 108, '陶瓷': 109}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [01:40<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104572 104572\n"
     ]
    }
   ],
   "source": [
    "def JudgeST(x):\n",
    "    return 1 if 'ST' in x else 0\n",
    "\n",
    "# 数据与rolling_day后的差\n",
    "def GetMA(df, col_name, rolling_day):\n",
    "    # reshape(-1) 扁平化 扁平化为1维数组\n",
    "    tmp_array = df[col_name].values.reshape(-1)\n",
    "    # tmp_array[:-rolling_day]: 0 ~ (tmp_array.size - rolling_day)\n",
    "    # tmp_array[rolling_day:]: rolling_day ~ tmp_array.size\n",
    "    # 从rolling_day行开始，计算(tmp_array[X + 5] - tmp_array[X]) / tmp_array[X]， 并赋值给df[rolling_day:, f'{col_name}_{str(rolling_day)}']\n",
    "    df.loc[rolling_day:, f'{col_name}_{str(rolling_day)}'] = ((tmp_array[:-rolling_day] - tmp_array[rolling_day:])) / tmp_array[:-rolling_day]\n",
    "    return df\n",
    "\n",
    "# ma: 收盘价的移动平均线，Moving Average\n",
    "# ma_v: 成交总量的移动平均线\n",
    "col = [f'ma{str(i)}' for i in [5, 10, 13, 21, 30]] + [f'ma_v_{str(i)}' for i in [5, 10, 13, 21, 30]]\n",
    "\n",
    "company_info = pd.read_csv(os.path.join(base_path, 'company_info.csv'), encoding=encoding_type)\n",
    "company_info['is_ST'] = company_info['name'].apply(JudgeST)\n",
    "# 丢弃一些多余的信息\n",
    "# drop([])，默认情况下删除某一行；\n",
    "# 如果要删除某列，需要axis=1；\n",
    "# 参数inplace 默认情况下为False，表示d保持原来的数据不变，True 则表示在原来的数据上改变。\n",
    "company_info.drop(['index', 'symbol', 'fullname'], axis=1, inplace=True)\n",
    "company_info.dropna(inplace=True)\n",
    "company_info['market'] = company_info['market'].map(market_map)\n",
    "company_info['exchange'] = company_info['exchange'].map(exchange_map)\n",
    "company_info['is_hs'] = company_info['is_hs'].map(is_hs_map)\n",
    "\n",
    "# 读取指数信息\n",
    "stock_index_info = pd.DataFrame()\n",
    "tmp_df = pd.read_csv(os.path.join(base_path,  'OldData', '000001.SH_NormalData.csv'))\n",
    "tmp_list = list(tmp_df['trade_date'].sort_values())\n",
    "date_map = dict(zip(tmp_list, range(len(tmp_list))))\n",
    "\n",
    "# 读取股票交易信息\n",
    "stock_info = pd.DataFrame()\n",
    "remove_stock = []\n",
    "tmp_list = []\n",
    "for ts_code in tqdm.tqdm(company_info['ts_code']):\n",
    "    try:\n",
    "        tmp_df = pd.read_csv(os.path.join(base_path, 'OldData', f'{ts_code}_NormalData.csv'))\n",
    "    except Exception:\n",
    "        continue\n",
    "    # 还需要去除一些停牌时间很久的企业，后期加\n",
    "    if len(tmp_df) < 120:  # 去除一些上市不久的企业\n",
    "        remove_stock.append(ts_code)\n",
    "        continue\n",
    "    tmp_df = tmp_df.sort_values('trade_date', ascending=True).reset_index(drop=True)\n",
    "    for tmp_col in col:\n",
    "        for rolling_day in [5]:\n",
    "            tmp_df = GetMA(tmp_df, tmp_col, rolling_day)\n",
    "    tmp_list.append(tmp_df)\n",
    "\n",
    "stock_info = pd.concat(tmp_list)\n",
    "stock_info = stock_info.reset_index(drop=True)\n",
    "ts_code_map = dict(zip(list(company_info['ts_code']), range(len(company_info))))\n",
    "\n",
    "\n",
    "stock_info = stock_info.reset_index(drop=True)\n",
    "stock_info['ts_code_id'] = stock_info['ts_code'].map(ts_code_map)\n",
    "\n",
    "stock_info['trade_date_id'] = stock_info['trade_date'].map(date_map)\n",
    "# 以 ts_code_id股票代码 和 trade_date_id股票日期 形成唯一索引\n",
    "stock_info['ts_date_id'] = (10000 + stock_info['ts_code_id']) * 10000 + stock_info['trade_date_id']\n",
    "stock_info = stock_info.merge(company_info, how='left', on='ts_code')\n",
    "stock_info_copy = stock_info.copy()\n",
    "\n",
    "# 移除重复数据， 针对nan?\n",
    "stock_info = stock_info.drop_duplicates(subset=['ts_date_id'])\n",
    "# len(stock_info) = len(ts_code) * len(ts_date)\n",
    "print(len(stock_info), len(stock_info_copy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取月份 和 星期几\n",
    "def get_weekday(x):\n",
    "    x = str(x)\n",
    "    return datetime.datetime.fromtimestamp(time.mktime(time.strptime(x, \"%Y%m%d\"))).weekday()\n",
    "\n",
    "stock_info['month'] = stock_info['trade_date'].apply(lambda x: int(str(x)[4:6]))\n",
    "stock_info['weekday'] = stock_info['trade_date'].apply(get_weekday)\n",
    "feature_col.append('month')\n",
    "feature_col.append('weekday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取每日涨跌停统计，如果某天涨停数远远多于跌停数，则说明市场赚钱效应显著\n",
    "# 添加涨跌停信息\n",
    "limit_info = pd.read_csv(os.path.join(base_path, 'limit.csv'))\n",
    "limit_info.drop('file', axis=1, inplace=True)\n",
    "limit_info['U-D'] = limit_info['U'] - limit_info['D']\n",
    "limit_info = limit_info.rename(columns={'date':'trade_date'})\n",
    "stock_info = stock_info.merge(limit_info[['U-D', 'trade_date']], on='trade_date', how='left')\n",
    "feature_col.append('U-D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将每日成交量做一些处理，利用10天成交量均线换算成比例，开盘价等也是如此\n",
    "\n",
    "# 求相对的vol(成交总量) 这里与10日成交均线比较\n",
    "stock_info['vol'] = (stock_info['vol'] - stock_info['ma_v_10']) / stock_info['ma_v_10']\n",
    "feature_col.append('vol')\n",
    "\n",
    "#转换low close等\n",
    "col = ['open', 'high', 'low', 'high', 'pre_close']\n",
    "for tmp_col in col:\n",
    "    stock_info[f'{tmp_col}_transform'] = (stock_info[tmp_col] - stock_info['ma10']) / stock_info['ma10']\n",
    "    feature_col.append(f'{tmp_col}_transform')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount_index_000001\n",
      "pre_close_index_000001\n",
      "amount\n",
      "pre_close\n"
     ]
    }
   ],
   "source": [
    "# 将大盘近五日相对于当天大盘情况换算成比例\n",
    "# 添加大盘指数信息\n",
    "tmp_df = pd.read_csv(os.path.join(base_path,  'OldData', '000001.SH' + '_NormalData.csv'))\n",
    "for tmp_col in ['amount', 'pre_close']:\n",
    "    tmp_df = tmp_df.rename(columns={tmp_col: f'{tmp_col}_index_000001'})\n",
    "    stock_info = stock_info.merge(tmp_df[['trade_date', f'{tmp_col}_index_000001']], on='trade_date', how='left')\n",
    "\n",
    "\n",
    "for tmp_col in ['amount_index_000001', 'pre_close_index_000001', 'amount', 'pre_close']:\n",
    "    print(tmp_col)\n",
    "    for i in range(5):\n",
    "        tmp_df = stock_info[['ts_date_id', tmp_col]]\n",
    "        new_col_name = f'{tmp_col}_shift_{i + 1}'\n",
    "        tmp_df = tmp_df.rename(columns={tmp_col:new_col_name})\n",
    "        feature_col.append(new_col_name)\n",
    "        tmp_df['ts_date_id'] = tmp_df['ts_date_id'] + i + 1\n",
    "        stock_info = stock_info.merge(tmp_df, how='left', on='ts_date_id')\n",
    "    for i in range(5):\n",
    "        new_col_name = f'{tmp_col}_shift_{i + 1}'\n",
    "        stock_info[new_col_name] = (stock_info[tmp_col] - stock_info[new_col_name]) / stock_info[new_col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col.append('turnover_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trade_date', 'ts_code', 'open', 'high', 'low', 'close', 'pre_close',\n",
       "       'change', 'pct_chg', 'vol', 'amount', 'turnover_rate', 'volume_ratio',\n",
       "       'ma5', 'ma_v_5', 'ma10', 'ma_v_10', 'ma13', 'ma_v_13', 'ma21',\n",
       "       'ma_v_21', 'ma30', 'ma_v_30', 'ma60', 'ma_v_60', 'ma120', 'ma_v_120',\n",
       "       'ma5_5', 'ma10_5', 'ma13_5', 'ma21_5', 'ma30_5', 'ma_v_5_5',\n",
       "       'ma_v_10_5', 'ma_v_13_5', 'ma_v_21_5', 'ma_v_30_5', 'ts_code_id',\n",
       "       'trade_date_id', 'ts_date_id', 'name', 'area', 'industry', 'market',\n",
       "       'exchange', 'list_date', 'is_hs', 'is_ST', 'month', 'weekday', 'U-D',\n",
       "       'open_transform', 'high_transform', 'low_transform',\n",
       "       'pre_close_transform', 'amount_index_000001', 'pre_close_index_000001',\n",
       "       'amount_index_000001_shift_1', 'amount_index_000001_shift_2',\n",
       "       'amount_index_000001_shift_3', 'amount_index_000001_shift_4',\n",
       "       'amount_index_000001_shift_5', 'pre_close_index_000001_shift_1',\n",
       "       'pre_close_index_000001_shift_2', 'pre_close_index_000001_shift_3',\n",
       "       'pre_close_index_000001_shift_4', 'pre_close_index_000001_shift_5',\n",
       "       'amount_shift_1', 'amount_shift_2', 'amount_shift_3', 'amount_shift_4',\n",
       "       'amount_shift_5', 'pre_close_shift_1', 'pre_close_shift_2',\n",
       "       'pre_close_shift_3', 'pre_close_shift_4', 'pre_close_shift_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_info.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征需要向前移一天，策略买入是第二天的开盘价，所以当天算出来的特征需要向前平移一天\n",
    "# 将特征向前平移一天也可以方便后期给大家推荐股票\n",
    "# 设置买入时间为第二天的开盘，买入价格开盘价\n",
    "stock_info['ts_date_id'] = stock_info['ts_date_id'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标签读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = os.path.join('stock', 'label', 'label.csv')\n",
    "label = pd.read_csv(label_path)\n",
    "label = label[['ts_code', 'trade_date', 'open', 'ts_date_id', 'label_final']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1134, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 311, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\n",
      "  File \"C:\\Users\\dllss\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py\", line 2062, in do_wait_suspend\n",
      "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
      "  File \"C:\\Users\\dllss\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py\", line 2098, in _do_wait_suspend\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [37], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m stock_info \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mmerge(stock_info, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mts_date_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m stock_info\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mstock_info\u001b[49m\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(stock_info)\n",
      "Cell \u001b[1;32mIn [37], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m stock_info \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mmerge(stock_info, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mts_date_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m stock_info\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mstock_info\u001b[49m\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(stock_info)\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1443\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:700\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1143\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1134\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:311\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2062\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2059\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2061\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001b[1;32m-> 2062\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2064\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2067\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2098\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2095\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2097\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2098\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2102\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stock_info.drop(['open', 'trade_date', 'ts_code'], axis=1, inplace=True)\n",
    "stock_info = label.merge(stock_info, on='ts_date_id', how='left')\n",
    "stock_info.to_csv('output.csv', index=False)\n",
    "stock_info.dropna(inplace=True)\n",
    "print(stock_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "stock_info = stock_info.reset_index(drop=True)\n",
    "print(len(stock_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>open</th>\n",
       "      <th>ts_date_id</th>\n",
       "      <th>label_final</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>change</th>\n",
       "      <th>...</th>\n",
       "      <th>amount_shift_1</th>\n",
       "      <th>amount_shift_2</th>\n",
       "      <th>amount_shift_3</th>\n",
       "      <th>amount_shift_4</th>\n",
       "      <th>amount_shift_5</th>\n",
       "      <th>pre_close_shift_1</th>\n",
       "      <th>pre_close_shift_2</th>\n",
       "      <th>pre_close_shift_3</th>\n",
       "      <th>pre_close_shift_4</th>\n",
       "      <th>pre_close_shift_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ts_code, trade_date, open, ts_date_id, label_final, high, low, close, pre_close, change, pct_chg, vol, amount, turnover_rate, volume_ratio, ma5, ma_v_5, ma10, ma_v_10, ma13, ma_v_13, ma21, ma_v_21, ma30, ma_v_30, ma60, ma_v_60, ma120, ma_v_120, ma5_5, ma10_5, ma13_5, ma21_5, ma30_5, ma_v_5_5, ma_v_10_5, ma_v_13_5, ma_v_21_5, ma_v_30_5, ts_code_id, trade_date_id, name, area, industry, market, exchange, list_date, is_hs, is_ST, month, weekday, U-D, open_transform, high_transform, low_transform, pre_close_transform, amount_index_000001, pre_close_index_000001, amount_index_000001_shift_1, amount_index_000001_shift_2, amount_index_000001_shift_3, amount_index_000001_shift_4, amount_index_000001_shift_5, pre_close_index_000001_shift_1, pre_close_index_000001_shift_2, pre_close_index_000001_shift_3, pre_close_index_000001_shift_4, pre_close_index_000001_shift_5, amount_shift_1, amount_shift_2, amount_shift_3, amount_shift_4, amount_shift_5, pre_close_shift_1, pre_close_shift_2, pre_close_shift_3, pre_close_shift_4, pre_close_shift_5]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 78 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trn_col = feature_col\n",
    "# 'high', 'low', 'close', 'pre_close',\n",
    "trn_col = list(set(trn_col))\n",
    "label = 'label_final'\n",
    "# trn_date_min = 20170103\n",
    "# trn_date_max = 20190416\n",
    "# val_date_min = 20190417\n",
    "# val_date_max = 20190429\n",
    "# test_date_min = 20190417\n",
    "# test_date_max = 20191218\n",
    "\n",
    "trn_date_min = 20160103\n",
    "trn_date_max = 20190101\n",
    "val_date_min = 20190101\n",
    "val_date_max = 20190419\n",
    "test_date_min = 20190101\n",
    "test_date_max = 20191218\n",
    "\n",
    "trn_data_idx = (stock_info['trade_date'] >= trn_date_min) & (stock_info['trade_date'] <= trn_date_max) & (stock_info['high']!=stock_info['close'])\n",
    "val_data_idx = (stock_info['trade_date'] >= val_date_min) & (stock_info['trade_date'] <= val_date_max)\n",
    "test_data_idx = (stock_info['trade_date'] >= test_date_min) & (stock_info['trade_date'] <= test_date_max)\n",
    "\n",
    "trn = stock_info[trn_data_idx][trn_col]\n",
    "trn_label = stock_info[trn_data_idx][label].values\n",
    "\n",
    "val = stock_info[val_data_idx][trn_col]\n",
    "val_label = stock_info[val_data_idx][label].values \n",
    "\n",
    "test = stock_info[test_data_idx][trn_col]\n",
    "test_label = stock_info[test_data_idx][label].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rate of 0: nan, rate of 1: nan\n",
      "trn data:0, val data:0, test data:0\n",
      "number of features:29\n",
      "['month', 'weekday', 'U-D', 'vol', 'open_transform', 'high_transform', 'low_transform', 'high_transform', 'pre_close_transform', 'amount_index_000001_shift_1', 'amount_index_000001_shift_2', 'amount_index_000001_shift_3', 'amount_index_000001_shift_4', 'amount_index_000001_shift_5', 'pre_close_index_000001_shift_1', 'pre_close_index_000001_shift_2', 'pre_close_index_000001_shift_3', 'pre_close_index_000001_shift_4', 'pre_close_index_000001_shift_5', 'amount_shift_1', 'amount_shift_2', 'amount_shift_3', 'amount_shift_4', 'amount_shift_5', 'pre_close_shift_1', 'pre_close_shift_2', 'pre_close_shift_3', 'pre_close_shift_4', 'pre_close_shift_5', 'turnover_rate']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dllss\\AppData\\Local\\Temp\\ipykernel_4712\\3594516288.py:2: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  print('rate of 0: %.4f, rate of 1: %.4f' % (np.sum(trn_label==0)/len(trn_label), np.sum(trn_label==1)/len(trn_label)))\n"
     ]
    }
   ],
   "source": [
    "# 使用的特征：星期；月份；当日涨停数-当日跌停数；转换后的开盘、收盘等价；近五日的收盘价、成交量（换成比例的）；\n",
    "print('rate of 0: %.4f, rate of 1: %.4f' % (np.sum(trn_label==0)/len(trn_label), np.sum(trn_label==1)/len(trn_label)))\n",
    "print('trn data:%d, val data:%d, test data:%d' % (len(trn), len(val), len(test)))\n",
    "print('number of features:%d' % len(trn_col))\n",
    "print(feature_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win_score_eval(preds, valid_df):\n",
    "    labels = valid_df.get_label()\n",
    "    preds = np.round(preds)\n",
    "    tp = np.sum((preds==1)&(labels==1))\n",
    "    pp = np.sum(preds==1)\n",
    "    scores = tp/(pp+0.001) + 2.5*tp - pp\n",
    "#     preds = np.argmax(preds.reshape(3, -1), axis=0)\n",
    "#     scores = f1_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    return 'win', scores, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input data must be 2 dimensional and non empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [18], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m num_round \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# clf = lgb.train(param, trn_data, num_round, valid_sets=[trn_data, val_data], verbose_eval=100,\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#                 early_stopping_rounds=300, feval=win_score_eval)\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m clf \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrn_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_round\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# oof_lgb = clf.predict(val, num_iteration=clf.best_iteration)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m test_lgb \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(test, num_iteration\u001b[38;5;241m=\u001b[39mclf\u001b[38;5;241m.\u001b[39mbest_iteration)\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:271\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m     booster \u001b[38;5;241m=\u001b[39m \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    273\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python310\\lib\\site-packages\\lightgbm\\basic.py:2605\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[0;32m   2599\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[0;32m   2600\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   2601\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[0;32m   2602\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2603\u001b[0m     )\n\u001b[0;32m   2604\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 2605\u001b[0m \u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2606\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   2607\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python310\\lib\\site-packages\\lightgbm\\basic.py:1815\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1812\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, used_indices)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[1;32m-> 1815\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1816\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1817\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1818\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1819\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[0;32m   1821\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python310\\lib\\site-packages\\lightgbm\\basic.py:1474\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1472\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical \u001b[38;5;241m=\u001b[39m reference\u001b[38;5;241m.\u001b[39mpandas_categorical\n\u001b[0;32m   1473\u001b[0m     categorical_feature \u001b[38;5;241m=\u001b[39m reference\u001b[38;5;241m.\u001b[39mcategorical_feature\n\u001b[1;32m-> 1474\u001b[0m data, feature_name, categorical_feature, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical \u001b[38;5;241m=\u001b[39m \u001b[43m_data_from_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1475\u001b[0m \u001b[43m                                                                                     \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1476\u001b[0m \u001b[43m                                                                                     \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1477\u001b[0m \u001b[43m                                                                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandas_categorical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1478\u001b[0m label \u001b[38;5;241m=\u001b[39m _label_from_pandas(label)\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;66;03m# process for args\u001b[39;00m\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python310\\lib\\site-packages\\lightgbm\\basic.py:566\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd_DataFrame):\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 566\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput data must be 2 dimensional and non empty.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m feature_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    568\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Input data must be 2 dimensional and non empty."
     ]
    }
   ],
   "source": [
    "# 模型训练及评价\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective': 'binary',\n",
    "         'learning_rate': 0.06,\n",
    "         \"boosting\": \"gbdt\",\n",
    "#          \"bagging_freq\": 1,\n",
    "#          \"bagging_seed\": 11,\n",
    "         \"metric\": 'None',\n",
    "         \"verbosity\": -1}\n",
    "trn_data = lgb.Dataset(trn, trn_label)\n",
    "val_data = lgb.Dataset(val, val_label)\n",
    "num_round =1000\n",
    "# clf = lgb.train(param, trn_data, num_round, valid_sets=[trn_data, val_data], verbose_eval=100,\n",
    "#                 early_stopping_rounds=300, feval=win_score_eval)\n",
    "clf = lgb.train(param, trn_data, num_round, verbose_eval=300)\n",
    "# oof_lgb = clf.predict(val, num_iteration=clf.best_iteration)\n",
    "test_lgb = clf.predict(test, num_iteration=clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "        'column': trn_col,\n",
    "        'importance': clf.feature_importance(),\n",
    "    }).sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lgb_final = np.round(oof_lgb)\n",
    "# print(metrics.accuracy_score(val_label, oof_lgb_final))\n",
    "# print(metrics.confusion_matrix(val_label, oof_lgb_final))\n",
    "# tp = np.sum(((oof_lgb_final == 1) & (val_label == 1)))\n",
    "# pp = np.sum(oof_lgb_final == 1)\n",
    "# print('sensitivity:%.3f'% (tp/(pp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_hold = 0.5\n",
    "# oof_test_final = (test_lgb >= 0.69) & (test_lgb <=0.7)\n",
    "oof_test_final = test_lgb >= thresh_hold\n",
    "print(metrics.accuracy_score(test_label, oof_test_final))\n",
    "print(metrics.confusion_matrix(test_label, oof_test_final))\n",
    "tp = np.sum(((oof_test_final == 1) & (test_label == 1)))\n",
    "pp = np.sum(oof_test_final == 1)\n",
    "print('accuracy:%.3f'% (tp/(pp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_postive_idx = np.argwhere(oof_test_final == 1).reshape(-1)\n",
    "# test_postive_idx = list(range(len(oof_test_final)))\n",
    "test_all_idx = np.argwhere(test_data_idx).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看选了哪些股票\n",
    "tmp_col = ['ts_code', 'name', 'trade_date', 'open', 'high', 'low', 'close', 'pre_close',\n",
    "       'change', 'pct_chg', 'amount', 'is_ST', 'label_final']\n",
    "# stock_info.iloc[test_all_idx[test_postive_idx]]\n",
    "\n",
    "tmp_df = stock_info[tmp_col].iloc[test_all_idx[test_postive_idx]].reset_index()\n",
    "tmp_df['label_prob'] = test_lgb[test_postive_idx]\n",
    "# idx_tmp = tmp_df['is_ST'] == 0\n",
    "# tmp_df.loc[idx_tmp, 'is_limit_up'] = (((tmp_df['close'][idx_tmp]-tmp_df['pre_close'][idx_tmp]) / tmp_df['pre_close'][idx_tmp]) > 0.095)\n",
    "# idx_tmp = tmp_df['is_ST'] == 1\n",
    "# tmp_df.loc[idx_tmp, 'is_limit_up'] = (((tmp_df['close'][idx_tmp]-tmp_df['pre_close'][idx_tmp]) / tmp_df['pre_close'][idx_tmp]) > 0.047)\n",
    "\n",
    "tmp_df['is_limit_up'] = tmp_df['close'] == tmp_df['high']\n",
    "\n",
    "buy_df = tmp_df[(tmp_df['is_limit_up']==False)].reset_index()\n",
    "buy_df.drop(['index', 'level_0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(buy_df), sum(buy_df['label_final']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_info.reset_index().head()\n",
    "# 读取指数信息\n",
    "index_df = pd.read_csv(os.path.join(base_path,  'OldData', '000001.SH' + '_NormalData.csv'))\n",
    "tmp_idx = (index_df['trade_date'] >= test_date_min) & (index_df['trade_date'] <= test_date_max)\n",
    "index_df = index_df.loc[tmp_idx].reset_index()\n",
    "index_df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tmp_idx \u001b[38;5;241m=\u001b[39m (\u001b[43mindex_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrade_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m test_date_min\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m close1 \u001b[38;5;241m=\u001b[39m index_df[tmp_idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m tmp_idx \u001b[38;5;241m=\u001b[39m (index_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrade_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m test_date_max)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'index_df' is not defined"
     ]
    }
   ],
   "source": [
    "tmp_idx = (index_df['trade_date'] == test_date_min+1)\n",
    "close1 = index_df[tmp_idx]['close'].values[0]\n",
    "tmp_idx = (index_df['trade_date'] == test_date_max)\n",
    "close2 = index_df[tmp_idx]['close'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "import Account\n",
    "reload(Account)\n",
    "money_init = 100000\n",
    "account = Account.Account(money_init, max_hold_period=20, stop_loss_rate=-0.07, stop_profit_rate=0.12)\n",
    "account.BackTest(buy_df, stock_info_copy, index_df, buy_price='open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df2 = buy_df[['ts_code', 'trade_date', 'label_prob', 'label_final']]\n",
    "tmp_df2 = tmp_df2.rename(columns={'trade_date':'buy_date'})\n",
    "tmp_df = account.info\n",
    "tmp_df = tmp_df.merge(tmp_df2, on=['ts_code', 'buy_date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_profit = (account.market_value - money_init) / money_init\n",
    "index_profit = (close2 - close1) / close1\n",
    "win_rate = account.victory / (account.victory + account.defeat)\n",
    "print('账户盈利情况:%.4f' % account_profit)\n",
    "print('上证指数浮动情况:%.4f' % index_profit)\n",
    "print('交易胜率:%.4f' % win_rate)\n",
    "print('最大回撤率:%.4f' % account.max_retracement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Draw\n",
    "reload(Draw)\n",
    "%matplotlib inline\n",
    "index_value = list(index_df[index_df['trade_date']==test_date_min+1]['pre_close']) + list(index_df.sort_values('trade_date')['close'])\n",
    "Draw.Draw_Market_Value_Change(0, account.market_value_all, index_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for ts_code, buy_date, sell_date in zip(account.info['ts_code'], account.info['buy_date'], account.info['sell_date']):\n",
    "    Draw.Draw_Stock(ts_code, stock_info, buy_date, sell_date, left_offset=10, right_offset=30)\n",
    "    num = num + 1\n",
    "    if num > 60:\n",
    "#         break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit ('3.10.3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "168078fbd95821fbdcaee015cbe93ae857c4e769fb6074e5de7144462aa268ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
